{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNNs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmYDwBpRbHHG",
        "colab_type": "text"
      },
      "source": [
        "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
        "\n",
        "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P59NYU98GCb9",
        "outputId": "a977edc0-1da4-490d-a1a4-d51ab2da9554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "!pip3 -qq install torch==0.4.1\n",
        "!pip3 -qq install bokeh==0.13.0\n",
        "!pip3 -qq install gensim==3.6.0\n",
        "!pip3 -qq install nltk\n",
        "!pip3 -qq install scikit-learn==0.20.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 519.5MB 29kB/s \n",
            "\u001b[31mERROR: fastai 1.0.52 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 16.0MB 4.4MB/s \n",
            "\u001b[?25h  Building wheel for bokeh (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 5.4MB 4.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8sVtGHmA9aBM",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from train import *\n",
        "from model import *\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-6CNKM3b4hT1"
      },
      "source": [
        "# Рекуррентные нейронные сети (RNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O_XkoGNQUeGm"
      },
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFEtWrS_4rUs"
      },
      "source": [
        "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
        "\n",
        "Мы порешаем сейчас POS Tagging для английского.\n",
        "\n",
        "Будем работать с таким набором тегов:\n",
        "- ADJ - adjective (new, good, high, ...)\n",
        "- ADP - adposition (on, of, at, ...)\n",
        "- ADV - adverb (really, already, still, ...)\n",
        "- CONJ - conjunction (and, or, but, ...)\n",
        "- DET - determiner, article (the, a, some, ...)\n",
        "- NOUN - noun (year, home, costs, ...)\n",
        "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
        "- PRT - particle (at, on, out, ...)\n",
        "- PRON - pronoun (he, their, her, ...)\n",
        "- VERB - verb (is, say, told, ...)\n",
        "- . - punctuation marks (. , ;)\n",
        "- X - other (ersatz, esprit, dunno, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EPIkKdFlHB-X"
      },
      "source": [
        "Скачаем данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TiA2dGmgF1rW",
        "outputId": "92ae805f-52b9-4a59-e69a-049e52bc4ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d93g_swyJA_V"
      },
      "source": [
        "Пример размеченного предложения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QstS4NO0L97c",
        "outputId": "ddb2ce15-7449-4751-fbe7-1c4b9f651ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "for word, tag in data[0]:\n",
        "    print('{:15}\\t{}'.format(word, tag))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The            \tDET\n",
            "Fulton         \tNOUN\n",
            "County         \tNOUN\n",
            "Grand          \tADJ\n",
            "Jury           \tNOUN\n",
            "said           \tVERB\n",
            "Friday         \tNOUN\n",
            "an             \tDET\n",
            "investigation  \tNOUN\n",
            "of             \tADP\n",
            "Atlanta's      \tNOUN\n",
            "recent         \tADJ\n",
            "primary        \tNOUN\n",
            "election       \tNOUN\n",
            "produced       \tVERB\n",
            "``             \t.\n",
            "no             \tDET\n",
            "evidence       \tNOUN\n",
            "''             \t.\n",
            "that           \tADP\n",
            "any            \tDET\n",
            "irregularities \tNOUN\n",
            "took           \tVERB\n",
            "place          \tNOUN\n",
            ".              \t.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "epdW8u_YXcAv"
      },
      "source": [
        "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
        "\n",
        "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xTai8Ta0lgwL",
        "outputId": "b7a82b50-5fa9-47a3-fe9c-520a9e394e05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
        "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
        "print('Words count in test set:', sum(len(sent) for sent in test_data))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words count in train set: 739769\n",
            "Words count in val set: 130954\n",
            "Words count in test set: 290469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eChdLNGtXyP0"
      },
      "source": [
        "Построим маппинги из слов в индекс и из тега в индекс:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pCjwwDs6Zq9x",
        "outputId": "35a0aaed-73fd-4a4a-87f3-56c6d681523f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "words = {word for sample in train_data for word, tag in sample}\n",
        "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
        "word2ind['<pad>'] = 0\n",
        "\n",
        "tags = {tag for sample in train_data for word, tag in sample}\n",
        "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
        "tag2ind['<pad>'] = 0\n",
        "\n",
        "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in train = 45441. Tags = {'PRON', 'NOUN', 'PRT', 'ADP', '.', 'VERB', 'X', 'ADJ', 'DET', 'ADV', 'NUM', 'CONJ'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "URC1B2nvPGFt",
        "outputId": "470e9b38-080e-49cb-e055-ee04d80b0c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
        "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "bar_width = 0.35\n",
        "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
        "plt.xticks(np.arange(len(tags)), tags)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAEyCAYAAABH+Yw/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHYZJREFUeJzt3X2QZXV95/H3JzOLZR4MKBNCAB3U\nQQPGjDKlVKJZFNHBpARTRodNZDCsoyVUVuNmxSRbuFE3mMRli41iYZwIWeUhGgNrjcEJakx2gzLI\nhCcFBkSZWYQJqGwWVwW/+8f9tRyanumevv3wa/r9qrrV93zPw/3e23fmfPqc87s3VYUkSZL69SOL\n3YAkSZL2zsAmSZLUOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHVu\n5WI3MNcOPPDAWr169WK3IUmSNK1rrrnmn6tq1XTLPeYC2+rVq9m2bdtityFJkjStJF+byXKeEpUk\nSeqcgU2SJKlzBjZJkqTOGdgkSZI6Z2CTJEnqnIFNkiSpcwY2SZKkzhnYJEmSOmdgkyRJ6ty0gS3J\n5iT3JLlhULskyfZ2uyPJ9lZfneQ7g3kfGKxzdJLrk+xIcm6StPoTk2xNcmv7eUCrpy23I8l1SZ47\n909fkiSpfzM5wvZhYP2wUFWvqaq1VbUW+DjwV4PZt03Mq6o3DurnAa8H1rTbxDbPBK6sqjXAlW0a\n4ITBspva+pIkScvOtN8lWlWfT7J6qnntKNmrgRfvbRtJDgaeUFVXtekLgZOATwEnAse2RS8APge8\nrdUvrKoCrkqyf5KDq+quaZ+VHuWcrbeMtf5bjj9ijjqRJEn7atxr2F4I3F1Vtw5qhye5NsnfJXlh\nqx0C7Bwss7PVAA4ahLBvAAcN1rlzD+s8QpJNSbYl2bZ79+4xno4kSVJ/xg1sJwMXDabvAp5cVc8B\nfhv4aJInzHRj7Wha7WsTVXV+Va2rqnWrVq3a19UlSZK6Nu0p0T1JshL4VeDoiVpVfRf4brt/TZLb\ngCOAXcChg9UPbTWAuydOdbZTp/e0+i7gsD2sI0mStGyMc4TtJcBXquqHpzqTrEqyot1/KqMBA7e3\nU573JzmmXfd2CnBZW+1yYGO7v3FS/ZQ2WvQY4NtevyZJkpajmXysx0XAPwLPSLIzyWlt1gYeeToU\n4JeA69rHfHwMeGNV3dfmvQn4M2AHcBujAQcAZwPHJ7mVUQg8u9W3ALe35T/Y1pckSVp2ZjJK9OQ9\n1E+dovZxRh/zMdXy24BnTVG/FzhuinoBp0/XnyRJ0mOd33QgSZLUOQObJElS5wxskiRJnTOwSZIk\ndc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHXOwCZJktQ5A5skSVLnDGySJEmdM7BJkiR1zsAmSZLU\nOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHXOwCZJktQ5A5skSVLn\nDGySJEmdM7BJkiR1zsAmSZLUOQObJElS5wxskiRJnZs2sCXZnOSeJDcMau9IsivJ9nZ7+WDe25Ps\nSHJzkpcN6utbbUeSMwf1w5N8odUvSbJfqz+uTe9o81fP1ZOWJElaSmZyhO3DwPop6udU1dp22wKQ\n5EhgA3BUW+f9SVYkWQG8DzgBOBI4uS0L8J62racD3wROa/XTgG+2+jltOUmSpGVn2sBWVZ8H7pvh\n9k4ELq6q71bVV4EdwPPabUdV3V5V3wMuBk5MEuDFwMfa+hcAJw22dUG7/zHguLa8JEnSsjLONWxn\nJLmunTI9oNUOAe4cLLOz1fZUfxLwrap6cFL9Edtq87/dlpckSVpWZhvYzgOeBqwF7gLeO2cdzUKS\nTUm2Jdm2e/fuxWxFkiRpzs0qsFXV3VX1UFX9APggo1OeALuAwwaLHtpqe6rfC+yfZOWk+iO21eb/\nZFt+qn7Or6p1VbVu1apVs3lKkiRJ3ZpVYEty8GDylcDECNLLgQ1thOfhwBrgi8DVwJo2InQ/RgMT\nLq+qAj4LvKqtvxG4bLCtje3+q4DPtOUlSZKWlZXTLZDkIuBY4MAkO4GzgGOTrAUKuAN4A0BV3Zjk\nUuAm4EHg9Kp6qG3nDOAKYAWwuapubA/xNuDiJO8CrgU+1OofAv4iyQ5Ggx42jP1sJUmSlqBpA1tV\nnTxF+UNT1CaWfzfw7inqW4AtU9Rv5+FTqsP6/wN+bbr+JEmSHuv8pgNJkqTOGdgkSZI6Z2CTJEnq\nnIFNkiSpcwY2SZKkzhnYJEmSOmdgkyRJ6pyBTZIkqXMGNkmSpM4Z2CRJkjpnYJMkSeqcgU2SJKlz\nBjZJkqTOGdgkSZI6Z2CTJEnqnIFNkiSpcwY2SZKkzhnYJEmSOmdgkyRJ6pyBTZIkqXMGNkmSpM4Z\n2CRJkjpnYJMkSeqcgU2SJKlzBjZJkqTOGdgkSZI6Z2CTJEnqnIFNkiSpc9MGtiSbk9yT5IZB7Y+T\nfCXJdUk+kWT/Vl+d5DtJtrfbBwbrHJ3k+iQ7kpybJK3+xCRbk9zafh7Q6mnL7WiP89y5f/qSJEn9\nm8kRtg8D6yfVtgLPqqpnA7cAbx/Mu62q1rbbGwf184DXA2vabWKbZwJXVtUa4Mo2DXDCYNlNbX1J\nkqRlZ9rAVlWfB+6bVPt0VT3YJq8CDt3bNpIcDDyhqq6qqgIuBE5qs08ELmj3L5hUv7BGrgL2b9uR\nJElaVubiGrbfBD41mD48ybVJ/i7JC1vtEGDnYJmdrQZwUFXd1e5/AzhosM6de1hHkiRp2Vg5zspJ\nfg94EPhIK90FPLmq7k1yNPDXSY6a6faqqpLULPrYxOi0KU9+8pP3dXVJkqSuzfoIW5JTgV8Bfr2d\n5qSqvltV97b71wC3AUcAu3jkadNDWw3g7olTne3nPa2+CzhsD+s8QlWdX1XrqmrdqlWrZvuUJEmS\nujSrwJZkPfAfgFdU1QOD+qokK9r9pzIaMHB7O+V5f5Jj2ujQU4DL2mqXAxvb/Y2T6qe00aLHAN8e\nnDqVJElaNqY9JZrkIuBY4MAkO4GzGI0KfRywtX06x1VtROgvAX+Q5PvAD4A3VtXEgIU3MRpx+nhG\n17xNXPd2NnBpktOArwGvbvUtwMuBHcADwOvGeaKSJElL1bSBrapOnqL8oT0s+3Hg43uYtw141hT1\ne4HjpqgXcPp0/UmSJD3W+U0HkiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHXOwCZJ\nktS5sb5LVJIW2jlbbxlr/bccf8QcdSJJC8cjbJIkSZ0zsEmSJHXOwCZJktQ5A5skSVLnDGySJEmd\nM7BJkiR1zsAmSZLUOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHXO\nwCZJktQ5A5skSVLnDGySJEmdM7BJkiR1zsAmSZLUOQObJElS52YU2JJsTnJPkhsGtScm2Zrk1vbz\ngFZPknOT7EhyXZLnDtbZ2Ja/NcnGQf3oJNe3dc5Nkr09hiRJ0nIy0yNsHwbWT6qdCVxZVWuAK9s0\nwAnAmnbbBJwHo/AFnAU8H3gecNYggJ0HvH6w3vppHkOSJGnZmFFgq6rPA/dNKp8IXNDuXwCcNKhf\nWCNXAfsnORh4GbC1qu6rqm8CW4H1bd4TquqqqirgwknbmuoxJEmSlo1xrmE7qKruave/ARzU7h8C\n3DlYbmer7a2+c4r63h7jEZJsSrItybbdu3fP8ulIkiT1aU4GHbQjYzUX25rNY1TV+VW1rqrWrVq1\naj7bkCRJWnDjBLa72+lM2s97Wn0XcNhguUNbbW/1Q6eo7+0xJEmSlo1xAtvlwMRIz43AZYP6KW20\n6DHAt9tpzSuAlyY5oA02eClwRZt3f5Jj2ujQUyZta6rHkCRJWjZWzmShJBcBxwIHJtnJaLTn2cCl\nSU4Dvga8ui2+BXg5sAN4AHgdQFXdl+SdwNVtuT+oqomBDG9iNBL18cCn2o29PIYkSdKyMaPAVlUn\n72HWcVMsW8Dpe9jOZmDzFPVtwLOmqN871WNIkiQtJ37TgSRJUucMbJIkSZ0zsEmSJHVuRtewSXps\nOmfrLWOt/5bjj5ijTiRJe+MRNkmSpM4Z2CRJkjrnKVFpDo1zitHTi5KkPfEImyRJUucMbJIkSZ0z\nsEmSJHXOwCZJktQ5A5skSVLnDGySJEmdM7BJkiR1zs9hkyQteX7Nmh7rPMImSZLUOQObJElS5wxs\nkiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHXOwCZJktQ5A5skSVLnDGySJEmdM7BJ\nkiR1zsAmSZLUuVkHtiTPSLJ9cLs/yZuTvCPJrkH95YN13p5kR5Kbk7xsUF/fajuSnDmoH57kC61+\nSZL9Zv9UJUmSlqZZB7aqurmq1lbVWuBo4AHgE232ORPzqmoLQJIjgQ3AUcB64P1JViRZAbwPOAE4\nEji5LQvwnratpwPfBE6bbb+SJElL1VydEj0OuK2qvraXZU4ELq6q71bVV4EdwPPabUdV3V5V3wMu\nBk5MEuDFwMfa+hcAJ81Rv5IkSUvGXAW2DcBFg+kzklyXZHOSA1rtEODOwTI7W21P9ScB36qqByfV\nHyXJpiTbkmzbvXv3+M9GkiSpI2MHtnZd2SuAv2yl84CnAWuBu4D3jvsY06mq86tqXVWtW7Vq1Xw/\nnCRJ0oJaOQfbOAH4UlXdDTDxEyDJB4FPtsldwGGD9Q5tNfZQvxfYP8nKdpRtuLwkSdKyMRenRE9m\ncDo0ycGDea8Ebmj3Lwc2JHlcksOBNcAXgauBNW1E6H6MTq9eXlUFfBZ4VVt/I3DZHPQrSZK0pIx1\nhC3JjwHHA28YlP8oyVqggDsm5lXVjUkuBW4CHgROr6qH2nbOAK4AVgCbq+rGtq23ARcneRdwLfCh\ncfqVJElaisYKbFX1fxkNDhjWXruX5d8NvHuK+hZgyxT12xmNIpUkSVq2/KYDSZKkzhnYJEmSOmdg\nkyRJ6pyBTZIkqXMGNkmSpM4Z2CRJkjpnYJMkSeqcgU2SJKlzBjZJkqTOGdgkSZI6Z2CTJEnqnIFN\nkiSpcwY2SZKkzhnYJEmSOmdgkyRJ6pyBTZIkqXMGNkmSpM4Z2CRJkjpnYJMkSeqcgU2SJKlzBjZJ\nkqTOGdgkSZI6Z2CTJEnqnIFNkiSpcwY2SZKkzhnYJEmSOrdysRuQJPXlnK23jLX+W44/Yo46kTTB\nI2ySJEmdGzuwJbkjyfVJtifZ1mpPTLI1ya3t5wGtniTnJtmR5Lokzx1sZ2Nb/tYkGwf1o9v2d7R1\nM27PkiRJS8lcHWF7UVWtrap1bfpM4MqqWgNc2aYBTgDWtNsm4DwYBTzgLOD5wPOAsyZCXlvm9YP1\n1s9Rz5IkSUvCfJ0SPRG4oN2/ADhpUL+wRq4C9k9yMPAyYGtV3VdV3wS2AuvbvCdU1VVVVcCFg21J\nkiQtC3MR2Ar4dJJrkmxqtYOq6q52/xvAQe3+IcCdg3V3ttre6junqD9Ckk1JtiXZtnv37nGfjyRJ\nUlfmYpToC6pqV5KfArYm+cpwZlVVkpqDx9mjqjofOB9g3bp18/pYkiRJC23sI2xVtav9vAf4BKNr\n0O5upzNpP+9pi+8CDhusfmir7a1+6BR1SZKkZWOswJbkx5L8xMR94KXADcDlwMRIz43AZe3+5cAp\nbbToMcC326nTK4CXJjmgDTZ4KXBFm3d/kmPa6NBTBtuSJElaFsY9JXoQ8In2SRsrgY9W1d8kuRq4\nNMlpwNeAV7fltwAvB3YADwCvA6iq+5K8E7i6LfcHVXVfu/8m4MPA44FPtZskSdKyMVZgq6rbgZ+f\non4vcNwU9QJO38O2NgObp6hvA541Tp+SJElLmd90IEmS1DkDmyRJUucMbJIkSZ0zsEmSJHXOwCZJ\nktQ5A5skSVLnDGySJEmdM7BJkiR1zsAmSZLUOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJ\nUucMbJIkSZ1budgNSJK0HJ2z9ZZZr/uW44+Yw060FHiETZIkqXMGNkmSpM4Z2CRJkjpnYJMkSeqc\ngU2SJKlzBjZJkqTO+bEeszDOUGxwOLYkSdo3HmGTJEnqnIFNkiSpcwY2SZKkzhnYJEmSOmdgkyRJ\n6tysA1uSw5J8NslNSW5M8u9a/R1JdiXZ3m4vH6zz9iQ7ktyc5GWD+vpW25HkzEH98CRfaPVLkuw3\n234lSZKWqnGOsD0IvLWqjgSOAU5PcmSbd05VrW23LQBt3gbgKGA98P4kK5KsAN4HnAAcCZw82M57\n2raeDnwTOG2MfiVJkpakWQe2qrqrqr7U7v8f4MvAIXtZ5UTg4qr6blV9FdgBPK/ddlTV7VX1PeBi\n4MQkAV4MfKytfwFw0mz7lSRJWqrm5Bq2JKuB5wBfaKUzklyXZHOSA1rtEODOwWo7W21P9ScB36qq\nByfVp3r8TUm2Jdm2e/fuOXhGkiRJ/Rj7mw6S/DjwceDNVXV/kvOAdwLVfr4X+M1xH2dvqup84HyA\ndevW1Xw+liRJWhoeS99MNFZgS/KvGIW1j1TVXwFU1d2D+R8EPtkmdwGHDVY/tNXYQ/1eYP8kK9tR\ntuHykiRJy8Y4o0QDfAj4clX9l0H94MFirwRuaPcvBzYkeVySw4E1wBeBq4E1bUTofowGJlxeVQV8\nFnhVW38jcNls+5UkSVqqxjnC9ovAa4Hrk2xvtd9lNMpzLaNToncAbwCoqhuTXArcxGiE6elV9RBA\nkjOAK4AVwOaqurFt723AxUneBVzLKCBKkiQtK7MObFX1D0CmmLVlL+u8G3j3FPUtU61XVbczGkUq\nSZK0bPlNB5IkSZ0zsEmSJHXOwCZJktS5sT+HTZov43x+Tk+fnSNJ0rg8wiZJktQ5A5skSVLnDGyS\nJEmdM7BJkiR1zsAmSZLUOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmS\nJHXOwCZJktS5lYvdgCRJ6t85W28Za/23HH/EHHWyPHmETZIkqXMGNkmSpM4Z2CRJkjpnYJMkSeqc\ngU2SJKlzBjZJkqTOGdgkSZI6Z2CTJEnqnIFNkiSpc90HtiTrk9ycZEeSMxe7H0mSpIXWdWBLsgJ4\nH3ACcCRwcpIjF7crSZKkhdV1YAOeB+yoqtur6nvAxcCJi9yTJEnSgur9y98PAe4cTO8Enr9IvUjS\nrIzzpdl+YbYkgFTVYvewR0leBayvqn/bpl8LPL+qzpi03CZgU5t8BnDzgjb6aAcC/7zIPewre55/\nS61fsOeFsNT6BXteKEut56XWL/TR81OqatV0C/V+hG0XcNhg+tBWe4SqOh84f6Gamk6SbVW1brH7\n2Bf2PP+WWr9gzwthqfUL9rxQllrPS61fWFo9934N29XAmiSHJ9kP2ABcvsg9SZIkLaiuj7BV1YNJ\nzgCuAFYAm6vqxkVuS5IkaUF1HdgAqmoLsGWx+9hH3Zye3Qf2PP+WWr9gzwthqfUL9rxQllrPS61f\nWEI9dz3oQJIkSf1fwyZJkrTsGdgkSZI6Z2CbRpKHkmxPckOSv0zyo1PU/0eS/QfrHJXkM+07UG9N\n8h+TpM07NckPkjx7sPwNSVbPUb+V5L2D6X+f5B2D6U1JvtJuX0zygsG8O5IcOJg+NsknF6LvKZ7H\njF/3JD/XatuT3Jfkq+3+385Hb3vp+aT2+j+zTa9O8p0k1yb5cnu9Tx0sf2qS3a3Xm5K8fiH77V2S\nzyZ52aTam5N8qr2u2we3U9r8O5Jcn+S6JH+X5CmDdSfeO/+U5EtJfmGhn9Ogl8Pa+/SJbfqANr16\nsXqabJbv5z9dpF4nfrc3tt/vW5P8SJt3bJJvT3q/vGZw/xtJdg2m91ugnmf8+rZ5Oyee02Ab25PM\n64fJ722fkuTDGX1e6nD5fxn0XEneNZh3YJLvz/f7JMlPJ7k4yW1JrkmyJckRGWPfnEn7x8VgYJve\nd6pqbVU9C/ge8MYp6vcBpwMkeTyjjx45u6qeAfw88AvAmwbb3An83jz1+13gV6d6YyX5FeANwAuq\n6pntuXw0yU/PcNvz2fdkM37dq+r6VlvL6LX/nTb9kgXqdcLJwD+0nxNuq6rnVNXPMvpYmjcned1g\n/iWt72OB/5zkoAXrtn8XMXrNhjYAf8jodV07uF04WOZFVfVs4HPA7w/qE++dnwfe3razKKrqTuA8\n4OxWOhs4v6ruWKyepjCb9/NimfjdHgUcz+j7p88azP/7Se+XSwb/Z3wAOGcw73sL1POMX9/2vvg6\n8MKJBVvQ+4mq+sI897nHfcoMfBX45cH0rwHz+kkPLYB9AvhcVT2tqo5m9O/9IBZ33zw2A9u++Xvg\n6VPU/5HR12gB/Bvgf1bVpwGq6gHgDODMwfKfBI5K8ox56PFBRqNe3jLFvLcxCjP/3Hr7EnABLWzO\nwHz2vTczed0XVZIfB14AnMajQwYAVXU78NvAb00x7x7gNuApk+ctYx8DfnniiEf7S/dneOTX1e3N\n3t4fTwC+OWZ/4zoHOCbJmxm9d/5kkfv5oXHfz4up/VvaBJwxcfSkN7N8fSf/AbOB0fdrz7e97VOm\n8wDw5SQTH0z7GuDSuWpsD14EfL+qPjBRqKp/Ao5gcffNYzOwzVCSlYz+art+Un0FcBwPf6DvUcA1\nw2Wq6jbgx5M8oZV+APwR8Lvz1O77gF9P8pOT6o/qDdjW6jMx330/yj687ovtROBvquoW4N4kR+9h\nuS8Bz5xcTPJU4KnAjvlrcWmpqvuALzL6/cNoB3UpUMDTJp3ieuEUm1gP/PVg+vFt2a8Afwa8cx7b\nn1ZVfR/4HUbB7c1tuhdjvZ8XWws7K4CfaqUXTnq/PG0R24PZvb6XAie1/xNhFH4umt82f2hP+5SZ\nuBjYkOQw4CHgf89pZ4/2LB69n4M+9s1jMbBN7/FJtjMKNl8HPjSp/g1Gh1q37uN2P8ror+vD56zT\npqruBy5k3//yneozXibX5q3vSebrdZ8vJ/PwX7sX88jTHEOT/+J/TXs+FwFvaCFFDxseVdjAwzuo\nyadE/36wzmeT7GIU9IY7tInTZs9kFOYu7OAIzAnAXYx2Mj2Z7fu5V5NPid62yP3s8+tbVXcDNwDH\nJVkLPFhVN8xrlw8/9p72KTPZZ/wNo9PUG4BL5r67ObdQ+7h91v0H53bgO+06hynrGV0MfwWj04rn\nAjcBvzRcsB09+Zequn9i/9C+xeG9jE5Tzof/yuivsz8f1G4CjgY+M6gdzcPXFNwLHMDDX4T7RCZ9\nKe4C9D1hX1/3RZPRheMvBn4uSTH6y74Y/VU62XOALw+mL6mqM+a/yyXrMuCcJM8FfrSqrsn0F+a/\nCPgW8BHgPzE6rfQIVfWP7ZqcVcA9c9rxDLWd7vHAMcA/JLm4qu5ajF6Gxnw/d6H9n/sQo9/tzy5y\nO48w5us78QfM3Szc0bUJU+1TJvYZwA+f2+R9xveSXAO8FTgSeMU893kj8Kop6r3sm2fNI2xjaufB\nfwt4aztU/RHgBUleAj8chHAuo8Osk30YeAmjncZc93Ufo0Popw3KfwS8J8mTWm9rgVOB97f5nwNe\n2+atAH4D+OxC9j1TU7zui+lVwF9U1VOqanVVHcboYtvDhgu1oPEnwH9b8A6XqKr6F0bvwc3sww6q\nqh4E3gyc0nYij9Au2F7BaIez4NqRvfMYnQr9OvDH9HMN25J+PydZxWggwZ9Wn58MP87r+1fAyxmd\nDl2I69d+aA/7lM8xOkswMbL2VKbeZ7wXeNsCnUH4DPC4JJsmCm3k5810sG8eh4FtDlTVtcB1wMlV\n9R1G1yf8fpKbGV17dTXwqGHMbTTSuTx8ncVcey/ww5E9VXU5ox3f/2rX8XwQ+I3BX/XvBJ6e5J+A\naxldT/XfF6HvGRm+7ovZR3v8T0yqfZzRyKSnpQ3TZ/Sf3blV9eeTN9CrNhz+Zxa5jYsYjegaBrbJ\n17BNNZDjrrbOxKCaiWvYtjM6NbOxqh6a7+b34PXA16tq4pT++4GfTfKvF6mfodm+n1cyGlG4GCZ+\ntzcCfwt8mtHR1QmTr2Gb6gjMQpn1/xdV9S1Gg2nubtfpLbTJ+5RPMhoUdk37d/WLTHFkqqpurKoL\nFqLBFtJfCbwko4/1uJHRiPBvMN6+eTHf34BfTSVJmgNJzgFurar3T7uwtIS0o7bbq2pRP5XAI2yS\npLEk+RTwbEaXhEiPGUlewego4tsXvRePsEmSJPXNI2ySJEmdM7BJkiR1zsAmSZLUOQObJElS5wxs\nkiRJnfv/NsZ85CfXrKcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gArQwbzWWkgi"
      },
      "source": [
        "## Бейзлайн\n",
        "\n",
        "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
        "\n",
        "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
        "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
        "\n",
        "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
        "\n",
        "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
        "\n",
        "Простейший вариант - униграммная модель, учитывающая только слово:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5rWmSToIaeAo",
        "outputId": "56cfaf59-2756-4133-bb51-e987d220bd5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "\n",
        "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
        "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigram tagger = 92.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "07Ymb_MkbWsF"
      },
      "source": [
        "Добавим вероятности переходов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vjz_Rk0bbMyH",
        "outputId": "e6d30d00-41f9-4519-c47c-57a327071e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
        "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of bigram tagger = 93.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uWMw6QHvbaDd"
      },
      "source": [
        "Обратите внимание, что `backoff` важен:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8XCuxEBVbOY_",
        "outputId": "9414ea1f-3bdf-4f39-ab08-9b81ed3e02c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "trigram_tagger = nltk.TrigramTagger(train_data, backoff=bigram_tagger)\n",
        "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of trigram tagger = 93.43%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4t3xyYd__8d-"
      },
      "source": [
        "## Увеличиваем контекст с рекуррентными сетями\n",
        "\n",
        "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
        "\n",
        "Омонимия - основная причина, почему униграмная модель плоха:  \n",
        "*“he cashed a check at the **bank**”*  \n",
        "vs  \n",
        "*“he sat on the **bank** of the river”*\n",
        "\n",
        "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
        "\n",
        "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
        "\n",
        "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
        "\n",
        "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RtRbz1SwgEqc",
        "colab": {}
      },
      "source": [
        "def convert_data(data, word2ind, tag2ind):\n",
        "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
        "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l4XsRII5kW5x",
        "outputId": "1bf0a5b5-6ef7-4170-ae21-fb5283471861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
        "\n",
        "X_batch.shape, y_batch.shape #это норма!"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 4), (32, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C5I9E9P6eFYv"
      },
      "source": [
        "**Задание** Реализуйте `LSTMTagger`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q_HA8zyheYGH"
      },
      "source": [
        "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jbrxsZ2mehWB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "49df85cd-aa25-42f0-a384-3eb514c72df3"
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ")\n",
        "\n",
        "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
        "\n",
        "logits = model(X_batch)\n",
        "\n",
        "preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "mask = (y_batch != 0).float()\n",
        "correct_count = ((preds == y_batch).float() * mask).sum().item()\n",
        "total_count = mask.sum().item()\n",
        "\n",
        "correct_count / total_count"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07608695652173914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GMUyUm1hgpe3",
        "outputId": "24592752-56c3-4a35-f31c-2f72c4f46e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "criterion(logits.reshape(logits.shape[0]*logits.shape[1], len(tag2ind)),\n",
        "          y_batch.reshape(y_batch.shape[0]*y_batch.shape[1]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5616, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nSgV3NPUpcjH"
      },
      "source": [
        "**Задание** Вставьте эти вычисление в функцию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pqfbeh1ltEYa",
        "outputId": "b232e6a0-e2dc-43bf-b16d-46241f13d9c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 10] Train: Loss = 0.67884, Accuracy = 78.59%: 100%|██████████| 572/572 [00:06<00:00, 85.24it/s]\n",
            "[1 / 10]   Val: Loss = 0.35092, Accuracy = 88.22%: 100%|██████████| 13/13 [00:00<00:00, 72.75it/s]\n",
            "[2 / 10] Train: Loss = 0.27239, Accuracy = 90.99%: 100%|██████████| 572/572 [00:06<00:00, 88.11it/s]\n",
            "[2 / 10]   Val: Loss = 0.22922, Accuracy = 92.32%: 100%|██████████| 13/13 [00:00<00:00, 77.56it/s]\n",
            "[3 / 10] Train: Loss = 0.18427, Accuracy = 93.89%: 100%|██████████| 572/572 [00:06<00:00, 88.06it/s]\n",
            "[3 / 10]   Val: Loss = 0.18292, Accuracy = 93.85%: 100%|██████████| 13/13 [00:00<00:00, 75.84it/s]\n",
            "[4 / 10] Train: Loss = 0.13801, Accuracy = 95.39%: 100%|██████████| 572/572 [00:06<00:00, 90.16it/s]\n",
            "[4 / 10]   Val: Loss = 0.15880, Accuracy = 94.61%: 100%|██████████| 13/13 [00:00<00:00, 77.06it/s]\n",
            "[5 / 10] Train: Loss = 0.10759, Accuracy = 96.37%: 100%|██████████| 572/572 [00:06<00:00, 89.62it/s]\n",
            "[5 / 10]   Val: Loss = 0.14707, Accuracy = 94.92%: 100%|██████████| 13/13 [00:00<00:00, 78.04it/s]\n",
            "[6 / 10] Train: Loss = 0.08584, Accuracy = 97.12%: 100%|██████████| 572/572 [00:06<00:00, 88.34it/s]\n",
            "[6 / 10]   Val: Loss = 0.14367, Accuracy = 95.05%: 100%|██████████| 13/13 [00:00<00:00, 71.91it/s]\n",
            "[7 / 10] Train: Loss = 0.06936, Accuracy = 97.66%: 100%|██████████| 572/572 [00:07<00:00, 80.76it/s]\n",
            "[7 / 10]   Val: Loss = 0.14343, Accuracy = 95.12%: 100%|██████████| 13/13 [00:00<00:00, 70.70it/s]\n",
            "[8 / 10] Train: Loss = 0.05645, Accuracy = 98.10%: 100%|██████████| 572/572 [00:06<00:00, 88.19it/s]\n",
            "[8 / 10]   Val: Loss = 0.14393, Accuracy = 95.23%: 100%|██████████| 13/13 [00:00<00:00, 75.81it/s]\n",
            "[9 / 10] Train: Loss = 0.04634, Accuracy = 98.43%: 100%|██████████| 572/572 [00:06<00:00, 90.01it/s]\n",
            "[9 / 10]   Val: Loss = 0.15293, Accuracy = 95.02%: 100%|██████████| 13/13 [00:00<00:00, 71.93it/s]\n",
            "[10 / 10] Train: Loss = 0.03834, Accuracy = 98.72%: 100%|██████████| 572/572 [00:06<00:00, 90.03it/s]\n",
            "[10 / 10]   Val: Loss = 0.15952, Accuracy = 95.05%: 100%|██████████| 13/13 [00:00<00:00, 70.41it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m0qGetIhfUE5"
      },
      "source": [
        "### Masking\n",
        "\n",
        "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
        "\n",
        "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAfV2dEOfHo5"
      },
      "source": [
        "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvk6Vz4CaY6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, data):\n",
        "    X_test, y_test = data\n",
        "    correct_count = 0\n",
        "    sum_count = 0\n",
        "    model.eval()\n",
        "    for i, (X_batch, y_batch) in enumerate(iterate_batches((X_test, y_test), 512)):\n",
        "        X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "        logits = model(X_batch)\n",
        "        preds = torch.argmax(logits, dim=-1)\n",
        "        mask = (y_batch != 0).float()\n",
        "        cur_correct_count, cur_sum_count = ((preds == y_batch).float() * mask).sum().item(), mask.sum().item()\n",
        "        correct_count += cur_correct_count\n",
        "        sum_count += cur_sum_count\n",
        "    return correct_count / sum_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "98wr38_rw55D",
        "outputId": "d00cfead-656a-4ead-975d-cc009217cb74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_model(model, (X_test, y_test))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9517814293435788"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXUTSFaEHbDG"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
        "\n",
        "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
        "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
        "\n",
        "**Задание** Добавьте Bidirectional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niGopLgdUgja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "58d0a40c-7084-4446-f15d-75af980217ef"
      },
      "source": [
        "model = BiLSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 10] Train: Loss = 0.62909, Accuracy = 80.89%: 100%|██████████| 572/572 [00:09<00:00, 58.80it/s]\n",
            "[1 / 10]   Val: Loss = 0.29418, Accuracy = 90.50%: 100%|██████████| 13/13 [00:00<00:00, 56.46it/s]\n",
            "[2 / 10] Train: Loss = 0.21950, Accuracy = 93.10%: 100%|██████████| 572/572 [00:09<00:00, 66.16it/s]\n",
            "[2 / 10]   Val: Loss = 0.19079, Accuracy = 93.92%: 100%|██████████| 13/13 [00:00<00:00, 56.02it/s]\n",
            "[3 / 10] Train: Loss = 0.14105, Accuracy = 95.66%: 100%|██████████| 572/572 [00:08<00:00, 66.23it/s]\n",
            "[3 / 10]   Val: Loss = 0.15017, Accuracy = 95.20%: 100%|██████████| 13/13 [00:00<00:00, 63.84it/s]\n",
            "[4 / 10] Train: Loss = 0.09924, Accuracy = 97.00%: 100%|██████████| 572/572 [00:08<00:00, 66.26it/s]\n",
            "[4 / 10]   Val: Loss = 0.12830, Accuracy = 95.88%: 100%|██████████| 13/13 [00:00<00:00, 60.20it/s]\n",
            "[5 / 10] Train: Loss = 0.07235, Accuracy = 97.82%: 100%|██████████| 572/572 [00:08<00:00, 66.20it/s]\n",
            "[5 / 10]   Val: Loss = 0.11964, Accuracy = 96.10%: 100%|██████████| 13/13 [00:00<00:00, 58.60it/s]\n",
            "[6 / 10] Train: Loss = 0.05366, Accuracy = 98.42%: 100%|██████████| 572/572 [00:09<00:00, 59.99it/s]\n",
            "[6 / 10]   Val: Loss = 0.11592, Accuracy = 96.29%: 100%|██████████| 13/13 [00:00<00:00, 64.26it/s]\n",
            "[7 / 10] Train: Loss = 0.03977, Accuracy = 98.86%: 100%|██████████| 572/572 [00:08<00:00, 65.90it/s]\n",
            "[7 / 10]   Val: Loss = 0.11308, Accuracy = 96.44%: 100%|██████████| 13/13 [00:00<00:00, 62.00it/s]\n",
            "[8 / 10] Train: Loss = 0.02965, Accuracy = 99.17%: 100%|██████████| 572/572 [00:08<00:00, 66.65it/s]\n",
            "[8 / 10]   Val: Loss = 0.11406, Accuracy = 96.46%: 100%|██████████| 13/13 [00:00<00:00, 59.95it/s]\n",
            "[9 / 10] Train: Loss = 0.02235, Accuracy = 99.39%: 100%|██████████| 572/572 [00:08<00:00, 67.15it/s]\n",
            "[9 / 10]   Val: Loss = 0.11801, Accuracy = 96.45%: 100%|██████████| 13/13 [00:00<00:00, 63.75it/s]\n",
            "[10 / 10] Train: Loss = 0.01675, Accuracy = 99.57%: 100%|██████████| 572/572 [00:08<00:00, 66.63it/s]\n",
            "[10 / 10]   Val: Loss = 0.12233, Accuracy = 96.46%: 100%|██████████| 13/13 [00:00<00:00, 56.96it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRyiVeJLcLQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "af0d2a14-9ed1-41be-9985-f9b87357f4a0"
      },
      "source": [
        "#!!!   overfit, because embedding weights change   !!!\n",
        "test_model(model, (X_test, y_test))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9647191266537909"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZTXmYGD_ANhm"
      },
      "source": [
        "### Предобученные эмбеддинги\n",
        "\n",
        "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
        "\n",
        "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uZpY_Q1xZ18h",
        "outputId": "4c89f008-741f-4324-8b58-d280957c6462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load('glove-wiki-gigaword-100')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KYogOoKlgtcf"
      },
      "source": [
        "Построим подматрицу для слов из нашей тренировочной выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VsCstxiO03oT",
        "outputId": "399ae29b-6c53-4a95-8ba6-8344d26b5d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "known_count = 0\n",
        "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
        "for word, ind in word2ind.items():\n",
        "    word = word.lower()\n",
        "    if word in w2v_model.vocab:\n",
        "        embeddings[ind] = w2v_model.get_vector(word)\n",
        "        known_count += 1\n",
        "embeddings = torch.Tensor(embeddings)\n",
        "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Know 38736 out of 45441 word embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HcG7i-R8hbY3"
      },
      "source": [
        "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EBtI6BDE-Fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "8a110bd0-35b7-4ad6-f9d5-ff9eeb5a3aa6"
      },
      "source": [
        "model = BiLSTMTagger(\n",
        "    vocab_size=embeddings.shape[0],\n",
        "    tagset_size=len(tag2ind),\n",
        "    word_emb_dim=embeddings.shape[1],\n",
        "    embeddings=embeddings,\n",
        "    freeze=False\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 10] Train: Loss = 0.40298, Accuracy = 88.76%: 100%|██████████| 572/572 [00:08<00:00, 69.81it/s]\n",
            "[1 / 10]   Val: Loss = 0.11479, Accuracy = 96.47%: 100%|██████████| 13/13 [00:00<00:00, 59.70it/s]\n",
            "[2 / 10] Train: Loss = 0.07167, Accuracy = 97.79%: 100%|██████████| 572/572 [00:08<00:00, 66.59it/s]\n",
            "[2 / 10]   Val: Loss = 0.08606, Accuracy = 97.23%: 100%|██████████| 13/13 [00:00<00:00, 60.46it/s]\n",
            "[3 / 10] Train: Loss = 0.04568, Accuracy = 98.55%: 100%|██████████| 572/572 [00:08<00:00, 66.33it/s]\n",
            "[3 / 10]   Val: Loss = 0.08623, Accuracy = 97.20%: 100%|██████████| 13/13 [00:00<00:00, 58.10it/s]\n",
            "[4 / 10] Train: Loss = 0.03329, Accuracy = 98.94%: 100%|██████████| 572/572 [00:09<00:00, 60.24it/s]\n",
            "[4 / 10]   Val: Loss = 0.09034, Accuracy = 97.06%: 100%|██████████| 13/13 [00:00<00:00, 58.53it/s]\n",
            "[5 / 10] Train: Loss = 0.02573, Accuracy = 99.17%: 100%|██████████| 572/572 [00:08<00:00, 61.01it/s]\n",
            "[5 / 10]   Val: Loss = 0.09309, Accuracy = 96.93%: 100%|██████████| 13/13 [00:00<00:00, 54.26it/s]\n",
            "[6 / 10] Train: Loss = 0.02024, Accuracy = 99.35%: 100%|██████████| 572/572 [00:09<00:00, 60.30it/s]\n",
            "[6 / 10]   Val: Loss = 0.10130, Accuracy = 96.85%: 100%|██████████| 13/13 [00:00<00:00, 60.67it/s]\n",
            "[7 / 10] Train: Loss = 0.01590, Accuracy = 99.50%: 100%|██████████| 572/572 [00:08<00:00, 66.88it/s]\n",
            "[7 / 10]   Val: Loss = 0.10991, Accuracy = 96.80%: 100%|██████████| 13/13 [00:00<00:00, 63.83it/s]\n",
            "[8 / 10] Train: Loss = 0.01250, Accuracy = 99.62%: 100%|██████████| 572/572 [00:08<00:00, 66.86it/s]\n",
            "[8 / 10]   Val: Loss = 0.11635, Accuracy = 96.76%: 100%|██████████| 13/13 [00:00<00:00, 63.33it/s]\n",
            "[9 / 10] Train: Loss = 0.00979, Accuracy = 99.71%: 100%|██████████| 572/572 [00:08<00:00, 66.27it/s]\n",
            "[9 / 10]   Val: Loss = 0.12793, Accuracy = 96.67%: 100%|██████████| 13/13 [00:00<00:00, 61.14it/s]\n",
            "[10 / 10] Train: Loss = 0.00736, Accuracy = 99.79%: 100%|██████████| 572/572 [00:08<00:00, 66.55it/s]\n",
            "[10 / 10]   Val: Loss = 0.12959, Accuracy = 96.73%: 100%|██████████| 13/13 [00:00<00:00, 65.06it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sirhK0qfySl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4886a17-a268-49cc-f3bf-38c57894f6e7"
      },
      "source": [
        "#freeze=True: 98.11% 96.93% 96.99%\n",
        "\n",
        "#!!!   overfit, because embedding weights change   !!!\n",
        "test_model(model, (X_test, y_test))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9675008348567317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Ne_8f24h8kg"
      },
      "source": [
        "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
        "\n",
        "Добейтесь качества лучше прошлых моделей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-brVuRgqhhyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_val = {word for sample in val_data for word, tag in sample}\n",
        "words_test = {word for sample in test_data for word, tag in sample}\n",
        "word2ind = {word: ind + 1 for ind, word in enumerate(words | words_val | words_test)}\n",
        "word2ind['<pad>'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HPUuAPGhEGVR",
        "colab": {}
      },
      "source": [
        "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9v7kdTfiUQc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3639d16a-ad2c-45d8-f9ef-4f1d6bf5f163"
      },
      "source": [
        "known_count = 0\n",
        "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
        "for word, ind in word2ind.items():\n",
        "    word = word.lower()\n",
        "    if word in w2v_model.vocab:\n",
        "        embeddings[ind] = w2v_model.get_vector(word)\n",
        "        known_count += 1\n",
        "embeddings = torch.Tensor(embeddings)\n",
        "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Know 46506 out of 56058 word embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUPe2sR7j4Y-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "d8665a29-0db0-45b3-fc35-65cb4358d7d7"
      },
      "source": [
        "model = BiLSTMTagger(\n",
        "    vocab_size=embeddings.shape[0],\n",
        "    tagset_size=len(tag2ind),\n",
        "    word_emb_dim=embeddings.shape[1],\n",
        "    embeddings=embeddings\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 10] Train: Loss = 0.56788, Accuracy = 83.78%: 100%|██████████| 572/572 [00:07<00:00, 78.52it/s]\n",
            "[1 / 10]   Val: Loss = 0.24526, Accuracy = 92.69%: 100%|██████████| 13/13 [00:00<00:00, 62.84it/s]\n",
            "[2 / 10] Train: Loss = 0.19085, Accuracy = 94.40%: 100%|██████████| 572/572 [00:07<00:00, 80.95it/s]\n",
            "[2 / 10]   Val: Loss = 0.16109, Accuracy = 95.26%: 100%|██████████| 13/13 [00:00<00:00, 64.12it/s]\n",
            "[3 / 10] Train: Loss = 0.13559, Accuracy = 95.95%: 100%|██████████| 572/572 [00:08<00:00, 69.19it/s]\n",
            "[3 / 10]   Val: Loss = 0.12686, Accuracy = 96.13%: 100%|██████████| 13/13 [00:00<00:00, 55.32it/s]\n",
            "[4 / 10] Train: Loss = 0.10917, Accuracy = 96.70%: 100%|██████████| 572/572 [00:07<00:00, 77.47it/s]\n",
            "[4 / 10]   Val: Loss = 0.10862, Accuracy = 96.66%: 100%|██████████| 13/13 [00:00<00:00, 59.21it/s]\n",
            "[5 / 10] Train: Loss = 0.09367, Accuracy = 97.15%: 100%|██████████| 572/572 [00:06<00:00, 82.19it/s]\n",
            "[5 / 10]   Val: Loss = 0.09918, Accuracy = 96.94%: 100%|██████████| 13/13 [00:00<00:00, 61.62it/s]\n",
            "[6 / 10] Train: Loss = 0.08337, Accuracy = 97.46%: 100%|██████████| 572/572 [00:06<00:00, 82.28it/s]\n",
            "[6 / 10]   Val: Loss = 0.09170, Accuracy = 97.15%: 100%|██████████| 13/13 [00:00<00:00, 65.15it/s]\n",
            "[7 / 10] Train: Loss = 0.07559, Accuracy = 97.68%: 100%|██████████| 572/572 [00:06<00:00, 84.24it/s]\n",
            "[7 / 10]   Val: Loss = 0.08906, Accuracy = 97.19%: 100%|██████████| 13/13 [00:00<00:00, 65.27it/s]\n",
            "[8 / 10] Train: Loss = 0.06968, Accuracy = 97.85%: 100%|██████████| 572/572 [00:07<00:00, 77.29it/s]\n",
            "[8 / 10]   Val: Loss = 0.08316, Accuracy = 97.37%: 100%|██████████| 13/13 [00:00<00:00, 54.80it/s]\n",
            "[9 / 10] Train: Loss = 0.06480, Accuracy = 98.00%: 100%|██████████| 572/572 [00:07<00:00, 73.92it/s]\n",
            "[9 / 10]   Val: Loss = 0.08086, Accuracy = 97.48%: 100%|██████████| 13/13 [00:00<00:00, 64.29it/s]\n",
            "[10 / 10] Train: Loss = 0.06068, Accuracy = 98.12%: 100%|██████████| 572/572 [00:07<00:00, 81.57it/s]\n",
            "[10 / 10]   Val: Loss = 0.08085, Accuracy = 97.45%: 100%|██████████| 13/13 [00:00<00:00, 61.82it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMpSyn-ckAqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ecbb2477-539b-4b60-829c-ef14a4a1b605"
      },
      "source": [
        "test_model(model, (X_test, y_test))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9748888865937501"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    }
  ]
}